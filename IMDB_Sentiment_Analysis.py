# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JzxSElLzMlBNpyXnbWCKvxY9yJTKoapM
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

from google.colab import drive
drive.mount('/content/drive')

!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews

import zipfile
with zipfile.ZipFile("imdb-dataset-of-50k-movie-reviews.zip", "r") as zip_ref:
    zip_ref.extractall("imdb-dataset-of-50k-movie-reviews-folder")

df = pd.read_csv('/content/imdb-dataset-of-50k-movie-reviews-folder/IMDB Dataset.csv')

df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})

X = df['review']
y = df['sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vocab_size = 10000  # You can adjust this
embedding_dim = 100
max_length = 200  # You can adjust this
trunc_type='post'
padding_type='post'
oov_tok = "<OOV>"

tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(X_train)

X_train_sequences = tokenizer.texts_to_sequences(X_train)
X_test_sequences = tokenizer.texts_to_sequences(X_test)

X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)
X_test_padded = pad_sequences(X_test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)

model = Sequential([
    Embedding(vocab_size, embedding_dim, input_length=max_length),
    LSTM(128),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

epochs = 5  # You can adjust this
batch_size = 64

history = model.fit(X_train_padded, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test_padded, y_test))

loss, accuracy = model.evaluate(X_test_padded, y_test)
print(f'Test Loss: {loss:.4f}')
print(f'Test Accuracy: {accuracy:.4f}')

def predict_sentiment(text):
    sequence = tokenizer.texts_to_sequences([text])
    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)
    prediction = model.predict(padded_sequence)[0]
    return "Positive" if prediction > 0.5 else "Negative"

# Example usage
review1 = "This movie was absolutely fantastic! The acting was superb, and the story kept me hooked until the end."
review2 = "I was really disappointed with this film. The plot was confusing, and the characters were uninteresting."

print(f"Review 1 Sentiment: {predict_sentiment(review1)}")
print(f"Review 2 Sentiment: {predict_sentiment(review2)}")

import pickle

# Save the model
model.save('sentiment_analysis_model.h5')

# Save the tokenizer
with open('tokenizer.pkl', 'wb') as tokenizer_file:
    pickle.dump(tokenizer, tokenizer_file)

!pip install flask pyngrok

!pip install streamlit
import streamlit as st
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle

# Load the model
@st.cache_resource
def load_model():
    return tf.keras.models.load_model('sentiment_analysis_model.h5')

model = load_model()

# Load the tokenizer
@st.cache_resource
def load_tokenizer():
    with open('tokenizer.pkl', 'rb') as tokenizer_file:
        return pickle.load(tokenizer_file)

tokenizer = load_tokenizer()

max_length = 200  # Make sure this matches your training
padding_type = 'post'
trunc_type = 'post'

def predict_sentiment(text):
    sequence = tokenizer.texts_to_sequences([text])
    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)
    prediction = model.predict(padded_sequence)[0]
    return "Positive" if prediction > 0.5 else "Negative"

st.title('IMDB Sentiment Analysis')

review_text = st.text_area("Enter Movie Review:", "")

if st.button('Predict Sentiment'):
    if review_text:
        sentiment = predict_sentiment(review_text)
        st.write(f'## Prediction: {sentiment}')
    else:
        st.warning('Please enter a movie review.')

!pip install streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py

!wget -q -O - ipv4.icanhazip.com

! streamlit run app.py & npx localtunnel --port 8501